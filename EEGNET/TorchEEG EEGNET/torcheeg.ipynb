{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJ/EQRfgpIeTJXxLfXv+bv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install torch torcheeg\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__.split('+')[0])\").html\n","!pip install --upgrade --force-reinstall numpy torch torchvision torchaudio\n","!pip uninstall -y numpy scipy scikit-learn torcheeg torch torchvision torchaudio jax jaxlib\n","!pip install numpy==1.26.4 scipy==1.10.1 scikit-learn torch torchvision torchaudio torcheeg --force-reinstall\n"],"metadata":{"id":"95bkw684JhJN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"5mpBIqNRJiG1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall torch torchvision torchaudio torch-scatter -y\n","!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n","!pip install shap\n","!pip install captum"],"metadata":{"id":"o4OtMS9iJi9N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torcheeg.models import EEGNet\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import shap\n","from captum.attr import LRP\n","\n","drive_path = \"/content/drive/MyDrive/FileStore/\"\n","preprocessed_folder = drive_path + \"preprocessed_eeg/\"\n","\n"],"metadata":{"id":"Uo_cM-MkJqFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LdvS6D-yJb4k"},"outputs":[],"source":["X_list, y_list = [], []\n","\n","\n","for file_name in sorted(os.listdir(preprocessed_folder)):\n","    if file_name.endswith(\".npy\") and not file_name.endswith(\"_label.npy\"):  # Ignore label files\n","        label_file = file_name.replace(\".npy\", \"_label.npy\")\n","        label_path = os.path.join(preprocessed_folder, label_file)\n","\n","        if os.path.exists(label_path):  # Ensure both X and y exist\n","            X = np.load(os.path.join(preprocessed_folder, file_name))  # EEG data\n","            y = np.load(label_path)  # Labels\n","\n","            X_list.append(X)\n","            y_list.append(y)\n","        else:\n","            print(f\"‚ö†Ô∏è Warning: Label file missing for {file_name}, skipping.\")\n","\n","# Merge all data into single NumPy arrays\n","X_all = np.concatenate(X_list, axis=0)  # Merge all trials into one dataset\n","y_all = np.concatenate(y_list, axis=0)\n","\n","print(f\"‚úÖ Merged Data Shape: X = {X_all.shape}, y = {y_all.shape}\")\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42, stratify=y_all)\n","\n","\n","# Convert to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","\n","# Create DataLoader\n","batch_size = 32\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","\n","# Define the Model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = EEGNet(\n","    chunk_size=250,  # Timepoints per trial\n","    num_electrodes=5,  # EEG channels\n","    num_classes=2,\n","    F1=64,\n","    D=8,\n","    F2=512,\n","    dropout=0.4\n",").to(device)\n","\n","# Define Loss Function & Optimizer\n","criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.Adam(model.parameters(), lr=0.001)\n","optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n","\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer,\n","    mode='min',\n","    factor=0.5,\n","    patience=5,\n","    verbose=True\n",")\n","\n","# Training Loop\n","num_epochs = 200\n","best_val_loss = float('inf')\n","early_stop_counter = 0\n","patience = 15\n","train_losses = []\n","val_losses = []\n","print(\"\\nüöÄ Starting Training...\")\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for batch_X, batch_y in train_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(batch_X)\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += batch_y.size(0)\n","        correct += (predicted == batch_y).sum().item()\n","\n","    train_acc = 100 * correct / total\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n","\n","    # Validation check (using test set loss here as proxy)\n","    model.eval()\n","    with torch.no_grad():\n","        val_outputs = model(X_test_tensor.to(device))\n","        val_loss = criterion(val_outputs, y_test_tensor.to(device)).item()\n","\n","    train_losses.append(running_loss)\n","    val_losses.append(val_loss)\n","\n","    scheduler.step(val_loss)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        early_stop_counter = 0\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= patience:\n","            print(f\"‚èπÔ∏è Early stopping triggered at epoch {epoch+1}!\")\n","            break\n","\n","# Evaluation on Test Set\n","print(\"\\nüîç Evaluating Model...\")\n","model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for batch_X, batch_y in test_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        outputs = model(batch_X)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == batch_y).sum().item()\n","        total += batch_y.size(0)\n","\n","test_acc = 100 * correct / total\n","print(f\"‚úÖ Model Evaluation Complete! Test Accuracy: {test_acc:.2f}%\")\n","\n","plt.figure(figsize=(10, 6))\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training vs Validation Loss\")\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]}]}